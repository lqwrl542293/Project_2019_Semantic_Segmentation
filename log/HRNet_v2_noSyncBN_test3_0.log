resume from 66
********
epoch:67    time:778.6305058002472
train_loss: 0.030504353106122227
********
epoch:68    time:1528.3552491664886
train_loss: 0.027524798970531533
resume from 66
resume from 100
********
epoch:101    time:719.6539595127106
train_loss: 0.1400234240110374
********
epoch:102    time:1511.518098115921
train_loss: 0.06132852600931318
********
epoch:103    time:2254.9907648563385
train_loss: 0.034635085035554486
********
epoch:104    time:2988.5267355442047
train_loss: 0.03022682711306445
********
epoch:105    time:3732.8879096508026
train_loss: 0.031126298405455822
********
epoch:106    time:4536.940737962723
train_loss: 0.22451881240890284
********
epoch:107    time:5334.356150150299
train_loss: 0.3298251141201366
resume from 100
********
epoch:101    time:870.5396595001221
train_loss: 0.03257643898027112
********
epoch:102    time:1667.3334670066833
train_loss: 0.07752457688176873
********
epoch:103    time:2399.592378616333
train_loss: 0.03228443379981148
********
epoch:104    time:3135.3677155971527
train_loss: 0.02757937673742723
********
epoch:105    time:3899.543246984482
train_loss: 0.04881374876607548
********
epoch:106    time:4645.263523340225
train_loss: 0.027783923791815535
********
epoch:107    time:5376.500816106796
train_loss: 0.026556475909571053
********
epoch:108    time:6121.667203426361
train_loss: 0.030555671269092897
********
epoch:109    time:6985.334232091904
train_loss: 0.02625845089203581
********
epoch:110    time:7720.345438718796
train_loss: 0.02637152963941948
********
epoch:111    time:8461.53015947342
train_loss: 0.0271678989633968
********
epoch:112    time:9199.042457580566
train_loss: 0.027365110802028317
********
epoch:113    time:9943.960826396942
train_loss: 0.02814378523540617
update learning rate: 0.000200 -> 0.000040
********
epoch:114    time:10690.030196666718
train_loss: 0.022512221313787228
********
epoch:115    time:11440.760383367538
train_loss: 0.02041648636236536
********
epoch:116    time:12176.76232266426
train_loss: 0.019867058971940667
********
epoch:117    time:12913.154068946838
train_loss: 0.019621041550078377
********
epoch:118    time:13701.065843820572
train_loss: 0.019376012750647285
********
epoch:119    time:14448.296144247055
train_loss: 0.019390577763971253
********
epoch:120    time:15190.496380090714
train_loss: 0.01905904125158835
********
epoch:121    time:15933.310187101364
train_loss: 0.018988947415417092
********
epoch:122    time:16671.992913246155
train_loss: 0.01890665916757351
********
epoch:123    time:17408.455316066742
train_loss: 0.018723164578454462
********
epoch:124    time:18262.43514943123
train_loss: 0.01867982390515431
********
epoch:125    time:18997.30045890808
train_loss: 0.018756950242752177
********
epoch:126    time:19845.846809864044
train_loss: 0.018355259251614613
********
epoch:127    time:20698.557970762253
train_loss: 0.018230725578361688
********
epoch:128    time:21434.415390491486
train_loss: 0.018127537768346694
********
epoch:129    time:22231.366769313812
train_loss: 0.018140736522046404
********
epoch:130    time:23009.66180872917
train_loss: 0.0179708715189587
********
epoch:131    time:23855.74542951584
train_loss: 0.017886855081350916
********
epoch:132    time:24710.12868642807
train_loss: 0.017742091219132197
********
epoch:133    time:25445.92343902588
train_loss: 0.017710576834226097
********
epoch:134    time:26346.746398687363
train_loss: 0.017605141799282346
********
epoch:135    time:27200.930204629898
train_loss: 0.01757866687608588
********
epoch:136    time:28010.7782702446
train_loss: 0.02374978778062244
********
epoch:137    time:28772.86064195633
train_loss: 0.018782971175983296
********
epoch:138    time:29541.1171066761
train_loss: 0.017177452574725503
********
epoch:139    time:30300.697234392166
train_loss: 0.016831511945184632
********
epoch:140    time:31188.89475941658
train_loss: 0.016987817054645783
********
epoch:141    time:31924.804609537125
train_loss: 0.016750099519988904
********
epoch:142    time:32739.757351398468
train_loss: 0.01670660379245526
********
epoch:143    time:33511.82972598076
train_loss: 0.017282323215645972
********
epoch:144    time:34286.30454468727
train_loss: 0.016962003251318178
********
epoch:145    time:35147.92870640755
train_loss: 0.016633772557783207
********
epoch:146    time:35883.94313907623
train_loss: 0.016490228975862765
********
epoch:147    time:36639.7352809906
train_loss: 0.016578547829003247
********
epoch:148    time:37479.09723806381
train_loss: 0.016547736404495007
********
epoch:149    time:38229.73861193657
train_loss: 0.01668356531158541
********
epoch:150    time:38966.86273312569
train_loss: 0.016606310589445963
update learning rate: 0.000040 -> 0.000008
********
epoch:151    time:39724.03807616234
train_loss: 0.015746397844293103
********
epoch:152    time:40460.3922662735
train_loss: 0.015395804709732935
********
epoch:153    time:41349.50123476982
train_loss: 0.015260815394647194
********
epoch:154    time:42173.730177640915
train_loss: 0.01526941596420626
********
epoch:155    time:43042.85689043999
train_loss: 0.01503928278820583
********
epoch:156    time:43778.62506508827
train_loss: 0.015134859996336679
********
epoch:157    time:44514.96203112602
train_loss: 0.01510718146257529
********
epoch:158    time:45255.17886829376
train_loss: 0.015071235942067924
********
epoch:159    time:45990.82190179825
train_loss: 0.01498656464044494
********
epoch:160    time:46731.46217107773
train_loss: 0.014985957465162783
********
epoch:161    time:47467.03082585335
train_loss: 0.014927736583858828
********
epoch:162    time:48236.83212161064
train_loss: 0.015042022908551726
********
epoch:163    time:48972.53682780266
train_loss: 0.014983898884795531
********
epoch:164    time:49707.60727882385
train_loss: 0.014990659712842016
********
epoch:165    time:50443.48170232773
train_loss: 0.014894382698894149
********
epoch:166    time:51178.09880781174
train_loss: 0.01487435973704062
********
epoch:167    time:51913.440556526184
train_loss: 0.014904712006976508
********
epoch:168    time:52651.66912603378
train_loss: 0.014783792116174393
********
epoch:169    time:53425.379989147186
train_loss: 0.014862885999709669
********
epoch:170    time:54160.60440707207
train_loss: 0.014827689770546425
********
epoch:171    time:54936.75517845154
train_loss: 0.014841466906922634
********
epoch:172    time:55680.58808994293
train_loss: 0.014724551762770923
********
epoch:173    time:56457.95026063919
train_loss: 0.01481858298483521
********
epoch:174    time:57203.65359854698
train_loss: 0.014738422401425012
********
epoch:175    time:57946.01000714302
train_loss: 0.014754696096911374
********
epoch:176    time:58682.38289999962
train_loss: 0.014728785241618502
update learning rate: 0.000008 -> 0.000002
********
epoch:177    time:59504.33109164238
train_loss: 0.014626022917453688
********
epoch:178    time:60240.931413412094
train_loss: 0.014505521005477367
********
epoch:179    time:60985.92993211746
train_loss: 0.014581904803035837
********
epoch:180    time:61730.93542981148
train_loss: 0.01443624298593111
********
epoch:181    time:62474.938328266144
train_loss: 0.0144588471349542
********
epoch:182    time:63210.73019647598
train_loss: 0.014479023786982905
********
epoch:183    time:63997.45036816597
train_loss: 0.014416154900484214
********
epoch:184    time:64734.40170240402
train_loss: 0.01449401753167512
********
epoch:185    time:65471.29164791107
train_loss: 0.014349122061347119
********
epoch:186    time:66218.14105892181
train_loss: 0.014394950065197367
********
epoch:187    time:66955.8920557499
train_loss: 0.01452751113384059
********
epoch:188    time:67706.66856598854
train_loss: 0.014383335585270064
********
epoch:189    time:68444.16642141342
train_loss: 0.014444862743243825
update learning rate: 0.000002 -> 0.000000
********
epoch:190    time:69191.48269462585
train_loss: 0.014412990435707047
Finish!
