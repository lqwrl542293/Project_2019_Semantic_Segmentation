********
epoch:1    time:660.8469495773315
train_loss: 0.7299093139492703
********
epoch:2    time:1376.6502220630646
train_loss: 0.458513258282183
********
epoch:3    time:2093.9109864234924
train_loss: 0.3603786932498919
********
epoch:4    time:2810.6509761810303
train_loss: 0.2874040650297897
********
epoch:5    time:3531.994701862335
train_loss: 0.25782026541152786
********
epoch:6    time:4270.893776893616
train_loss: 0.1984172424784413
********
epoch:7    time:4991.846928834915
train_loss: 0.1600262223169057
********
epoch:8    time:5711.7996344566345
train_loss: 0.14284275733059906
********
epoch:9    time:6498.361486196518
train_loss: 0.1393794095275378
********
epoch:10    time:7219.912498474121
train_loss: 0.11133252962269767
********
epoch:11    time:7973.364118337631
train_loss: 0.09388359628542504
********
epoch:12    time:8695.421798944473
train_loss: 0.08602630284298149
********
epoch:13    time:9453.999838113785
train_loss: 0.14704641509136368
********
epoch:14    time:10175.164541482925
train_loss: 0.08207774260128388
********
epoch:15    time:10941.291816711426
train_loss: 0.0738279727547859
********
epoch:16    time:11706.46358036995
train_loss: 0.06692411907343351
********
epoch:17    time:12431.404399394989
train_loss: 0.06433158513371792
********
epoch:18    time:13151.807171106339
train_loss: 0.06058009897016917
********
epoch:19    time:13959.750179290771
train_loss: 0.06049763430098091
********
epoch:20    time:14690.64854478836
train_loss: 0.14568903900507324
********
epoch:21    time:15417.755407333374
train_loss: 0.07820381030992225
********
epoch:22    time:16137.105551242828
train_loss: 0.06093756877111666
********
epoch:23    time:16867.01859354973
train_loss: 0.06458985575973386
update learning rate: 0.000200 -> 0.000040
********
epoch:24    time:17627.263303279877
train_loss: 0.049727656248241964
********
epoch:25    time:18387.717928171158
train_loss: 0.04593274798808676
********
epoch:26    time:19110.498987674713
train_loss: 0.04417497604483306
********
epoch:27    time:19831.39874815941
train_loss: 0.04301180479803471
********
epoch:28    time:20552.09230875969
train_loss: 0.04200880426399234
********
epoch:29    time:21275.984303951263
train_loss: 0.041124506605795336
********
epoch:30    time:22037.465710163116
train_loss: 0.04062352995529319
********
epoch:31    time:22796.15051674843
train_loss: 0.03953671872440211
********
epoch:32    time:23518.541890621185
train_loss: 0.038738701436104195
********
epoch:33    time:24239.798063755035
train_loss: 0.038282289461355014
********
epoch:34    time:24994.286789655685
train_loss: 0.03745319316107215
********
epoch:35    time:25714.3920648098
train_loss: 0.037220848304053346
********
epoch:36    time:26434.929272651672
train_loss: 0.036467594147882476
********
epoch:37    time:27155.096650123596
train_loss: 0.035642254740150286
********
epoch:38    time:27873.50387239456
train_loss: 0.035573778730450256
********
epoch:39    time:28594.812376260757
train_loss: 0.03491948200671962
********
epoch:40    time:29334.146014928818
train_loss: 0.034124576050775624
********
epoch:41    time:30051.986759901047
train_loss: 0.034000088068772645
********
epoch:42    time:30773.410816669464
train_loss: 0.03329599029713809
********
epoch:43    time:31501.881442070007
train_loss: 0.03300055461976464
********
epoch:44    time:32235.16547346115
train_loss: 0.03259730894080918
********
epoch:45    time:32968.15105652809
train_loss: 0.031774363207696665
********
epoch:46    time:33684.68637609482
train_loss: 0.03172805557272049
********
epoch:47    time:34405.645011901855
train_loss: 0.03134977365357908
********
epoch:48    time:35121.45254158974
train_loss: 0.030933017293712506
********
epoch:49    time:35886.69886350632
train_loss: 0.0307124894588985
********
epoch:50    time:36610.847771406174
train_loss: 0.030230856616589356
********
epoch:51    time:37331.61034798622
train_loss: 0.029875420905674747
********
epoch:52    time:38064.83206701279
train_loss: 0.02965063946666541
********
epoch:53    time:38786.332421302795
train_loss: 0.029381530948911452
********
epoch:54    time:39502.75210118294
train_loss: 0.029139891737187753
********
epoch:55    time:40221.14477753639
train_loss: 0.028663770135755492
********
epoch:56    time:40938.29212999344
train_loss: 0.02862320592633201
********
epoch:57    time:41656.17641377449
train_loss: 0.028168502310761297
********
epoch:58    time:42374.06606531143
train_loss: 0.027961562227721167
********
epoch:59    time:43095.38340854645
train_loss: 0.027664580297741024
********
epoch:60    time:43811.08474135399
train_loss: 0.02748024119973584
********
epoch:61    time:44522.272755384445
train_loss: 0.027178847767186886
********
epoch:62    time:45217.309973955154
train_loss: 0.02716333698794898
********
epoch:63    time:45910.61690926552
train_loss: 0.02672745780360819
********
epoch:64    time:46602.9271132946
train_loss: 0.02674554498483637
********
epoch:65    time:47295.44952535629
train_loss: 0.026501161049461926
********
epoch:66    time:47990.22215127945
train_loss: 0.02627204511603121
********
epoch:67    time:48683.98815655708
train_loss: 0.026717964741667915
********
epoch:68    time:49376.486937999725
train_loss: 0.02562371747386375
********
epoch:69    time:50070.458960056305
train_loss: 0.02564547648684746
********
epoch:70    time:50776.55631518364
train_loss: 0.0254170201869324
********
epoch:71    time:51472.110072374344
train_loss: 0.02552185397005643
********
epoch:72    time:52168.83022522926
train_loss: 0.025644565233176805
********
epoch:73    time:52862.82912993431
train_loss: 0.02498316344638866
********
epoch:74    time:53557.88871741295
train_loss: 0.02472218449669655
********
epoch:75    time:54262.20456576347
train_loss: 0.026483404214936074
********
epoch:76    time:54953.88744735718
train_loss: 0.024218278551342513
********
epoch:77    time:55648.73222732544
train_loss: 0.024152675687463997
********
epoch:78    time:56342.542181015015
train_loss: 0.024122154829327506
********
epoch:79    time:57038.086497068405
train_loss: 0.024095265445634974
********
epoch:80    time:57732.887404203415
train_loss: 0.024009848521514374
********
epoch:81    time:58426.68762540817
train_loss: 0.023867914885884585
********
epoch:82    time:59130.14465737343
train_loss: 0.023761735081371634
********
epoch:83    time:59830.93965435028
train_loss: 0.02360748281382551
********
epoch:84    time:60526.76987743378
train_loss: 0.023608892773488155
********
epoch:85    time:61230.6381790638
train_loss: 0.023364107579193532
********
epoch:86    time:61927.014305353165
train_loss: 0.023456423207866624
********
epoch:87    time:62624.67239165306
train_loss: 0.023103467944495203
********
epoch:88    time:63324.266602277756
train_loss: 0.02303882856360991
********
epoch:89    time:64032.67568349838
train_loss: 0.023089613257484
********
epoch:90    time:64729.32584786415
train_loss: 0.0227496385800116
********
epoch:91    time:65432.41803979874
train_loss: 0.02239156185777902
********
epoch:92    time:66127.44218873978
train_loss: 0.0224361306100281
********
epoch:93    time:66822.08803415298
train_loss: 0.02242175641435164
********
epoch:94    time:67526.2665886879
train_loss: 0.022273846045889036
********
epoch:95    time:68229.0761628151
train_loss: 0.022151092029731683
********
epoch:96    time:68932.09168744087
train_loss: 0.02223559585007955
********
epoch:97    time:69636.53241634369
train_loss: 0.02201178638571842
********
epoch:98    time:70346.41922211647
train_loss: 0.022145702425227422
********
epoch:99    time:71044.02436995506
train_loss: 0.02189918306439814
********
epoch:100    time:71750.99924659729
train_loss: 0.021702287555593835
********
epoch:101    time:72443.56440496445
train_loss: 0.02164210434940327
********
epoch:102    time:73143.95760536194
train_loss: 0.021419003480411942
********
epoch:103    time:73835.7958536148
train_loss: 0.021311612392114068
********
epoch:104    time:74528.62848687172
train_loss: 0.021224275544938012
********
epoch:105    time:75219.66168475151
train_loss: 0.021225327575698446
********
epoch:106    time:75904.05934667587
train_loss: 0.021201318399573014
********
epoch:107    time:76598.67886352539
train_loss: 0.0219095618674149
********
epoch:108    time:77280.81035685539
train_loss: 0.021484978986207885
********
epoch:109    time:77968.11710643768
train_loss: 0.02060116508894095
********
epoch:110    time:78651.80014324188
train_loss: 0.021596002207460628
********
epoch:111    time:79335.58378744125
train_loss: 0.020474282548032224
********
epoch:112    time:80025.99159288406
train_loss: 0.020860080077290937
********
epoch:113    time:80708.26522231102
train_loss: 0.020256633340359136
********
epoch:114    time:81390.1306014061
train_loss: 0.020419725019371872
********
epoch:115    time:82082.70272135735
train_loss: 0.02030019290268622
********
epoch:116    time:82771.69114971161
train_loss: 0.020253393604649037
********
epoch:117    time:83456.07644438744
train_loss: 0.02135513389878201
********
epoch:118    time:84142.61068320274
train_loss: 0.020418034502703332
********
epoch:119    time:84828.60558795929
train_loss: 0.019872289796921138
********
epoch:120    time:85520.55739402771
train_loss: 0.01981002457364641
********
epoch:121    time:86199.77464842796
train_loss: 0.019855759699236263
********
epoch:122    time:86885.87356305122
train_loss: 0.01991320812842661
********
epoch:123    time:87572.13191223145
train_loss: 0.01961160930946018
********
epoch:124    time:88261.3217074871
train_loss: 0.019791191914165864
********
epoch:125    time:88952.35428738594
train_loss: 0.019638406451452862
********
epoch:126    time:89634.45212626457
train_loss: 0.019627159843942532
********
epoch:127    time:90319.19088506699
train_loss: 0.019614135664621186
update learning rate: 0.000040 -> 0.000008
********
epoch:128    time:91002.95055317879
train_loss: 0.01833703952154728
********
epoch:129    time:91688.94810342789
train_loss: 0.017872711282963503
********
epoch:130    time:92375.00979447365
train_loss: 0.017915434922132427
********
epoch:131    time:93074.98688817024
train_loss: 0.01760998616929508
********
epoch:132    time:93761.27610349655
train_loss: 0.017627814533784734
********
epoch:133    time:94443.9709122181
train_loss: 0.01759111360718907
********
epoch:134    time:95130.33836722374
train_loss: 0.01767362132417634
********
epoch:135    time:95815.34613013268
train_loss: 0.017508591556614297
********
epoch:136    time:96500.15673136711
train_loss: 0.01754551630166143
********
epoch:137    time:97186.89024925232
train_loss: 0.017523129379709162
********
epoch:138    time:97868.98311066628
train_loss: 0.017505766250042604
********
epoch:139    time:98552.90708136559
train_loss: 0.017398681936892195
********
epoch:140    time:99233.75705552101
train_loss: 0.017398589409837618
********
epoch:141    time:99922.54816317558
train_loss: 0.017356080216314858
********
epoch:142    time:100605.11522221565
train_loss: 0.017358293857187134
********
epoch:143    time:101291.02232861519
train_loss: 0.017326347485987426
********
epoch:144    time:101976.44960618019
train_loss: 0.01734616428688921
********
epoch:145    time:102661.81033420563
train_loss: 0.017283456782600293
********
epoch:146    time:103345.07747292519
train_loss: 0.01722170734897206
********
epoch:147    time:104024.63101172447
train_loss: 0.017355718863155907
********
epoch:148    time:104698.39369773865
train_loss: 0.01724409259642515
********
epoch:149    time:105379.481954813
train_loss: 0.017302945598031735
********
epoch:150    time:106060.9932346344
train_loss: 0.017149501796874536
********
epoch:151    time:106740.60204958916
train_loss: 0.01721794840563026
********
epoch:152    time:107420.46864628792
train_loss: 0.017159468607243263
********
epoch:153    time:108099.12527751923
train_loss: 0.017166208344125987
********
epoch:154    time:108775.10890436172
train_loss: 0.01705876782047327
********
epoch:155    time:109450.0536544323
train_loss: 0.01707730085435339
********
epoch:156    time:110118.84366869926
train_loss: 0.016986032192178247
********
epoch:157    time:110794.54413723946
train_loss: 0.01719165507779278
********
epoch:158    time:111464.1217443943
train_loss: 0.016855257290481318
********
epoch:159    time:112131.65917468071
train_loss: 0.017040280079600786
********
epoch:160    time:112800.28868246078
train_loss: 0.01701728858191658
********
epoch:161    time:113468.97793126106
train_loss: 0.017012150484679724
********
epoch:162    time:114133.12226939201
train_loss: 0.016950310377234764
update learning rate: 0.000008 -> 0.000002
********
epoch:163    time:114802.94762182236
train_loss: 0.016888189938559076
update learning rate: 0.000002 -> 0.000000
********
epoch:164    time:115477.60753273964
train_loss: 0.01678829300546586
********
epoch:165    time:116154.44919705391
train_loss: 0.016729564010871178
********
epoch:166    time:116825.04699444771
train_loss: 0.01660041532382018
********
epoch:167    time:117506.05726766586
train_loss: 0.016650178529297063
********
epoch:168    time:118187.43431091309
train_loss: 0.016611969772638496
********
epoch:169    time:118870.26527404785
train_loss: 0.01661362038041004
********
epoch:170    time:119547.83055639267
train_loss: 0.016633261001421144
Finish!
